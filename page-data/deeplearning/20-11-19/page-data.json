{"componentChunkName":"component---src-templates-post-js","path":"/deeplearning/20-11-19/","result":{"data":{"markdownRemark":{"html":"<p> 실험용 워크스테이션 서버에 GeForce RTX 3090을 장착하여 사용하게 되었습니다. 직접 GPU를 교체하지는 않았고 기사님께서 오셔서 설치를 해주셨는데, GPU 장착 이후에 제가 Ubuntu 18.04 x86_64 운영체제 위에서 실험 환경을 구축했던 과정들을 아래에 공유합니다🤗</p>\n<ol>\n<li>CUDA toolkit과 driver 삭제</li>\n<li>CUDA toolkit 11 설치</li>\n<li>cudnn 8 설치</li>\n<li>tf-nightly 2.5.0 설치</li>\n<li>libcusolver.so.10 에러 해결</li>\n</ol>\n<p>RTX 30 시리즈는 CUDA 버전 11이상만이 호환되고, 이에 따라 cudnn 버전 8이상과 tensorflow 버전 2.5이상의 설치가 필수적이기 때문에 이런 순서로 설치를 진행했습니다.</p>\n<h3>설치 과정</h3>\n<h5>1. CUDA toolkit과 driver 삭제</h5>\n<p> 새로운 버전의 CUDA toolkit을 설치하기 위해서 이전 버전의 CUDA toolkit을 삭제해야합니다. 만약 CUDA toolkit은 없고 driver API만 존재하는 경우에도, 이전 버전의 파일이 존재한다는 이유로 설치가 취소되는 경우가 자주 발생하기 때문에 🤯 CUDA toolkit과 driver를 둘 다 삭제해 주었습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token function\">sudo</span> <span class=\"token function\">apt-get</span> --purge -y remove <span class=\"token string\">'cuda*'</span>\n<span class=\"token function\">sudo</span> <span class=\"token function\">apt-get</span> --purge -y remove <span class=\"token string\">'nvidia*'</span></code></pre></div>\n<p>혹은 CUDA toolkit을 아래의 명령어를 통해 삭제하셔도 됩니다. /usr/local/ 디렉토리 내 cuda 관련 디렉토리가 남아있다면 이것 또한 지워줍니다. <em>명령어 내  x 표시가 되어있는 부분은 본인 환경에 맞는 버전으로 꼭 수정해 주시길 바랍니다.</em></p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token function\">sudo</span> /usr/local/cuda/bin/uninstall_cuda_x.x.pl\n\n<span class=\"token function\">rm</span> -rf /usr/local/cuda\n<span class=\"token function\">rm</span> -rf /usr/local/cuda-x.x</code></pre></div>\n<p>남아있는 nvidia 관련 파일은 아래의 명령어를 통해 확인 가능합니다. 남아있는 것들도 똑같이 <code class=\"language-text\">apt-get --purge remove</code> 명령어를 사용하여 삭제합니다. </p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">dpkg -l <span class=\"token operator\">|</span> <span class=\"token function\">grep</span> -i nvidia</code></pre></div>\n<h5>2. CUDA toolkit 11 설치</h5>\n<p> 다음으로는 아래 명령어를 통해 버전 11을 설치하겠습니다. 설치를 완료하면 /usr/local/ 디렉토리 내에 cuda-11 디렉토리가 생성되며, driver API 또한 자동으로 설치됩니다.</p>\n<p><em>주의: 아래 명령어는 ubuntu 18.04 x86_64 운영체제를 위한 설치 명령어입니다. 다른 운영체제를 사용하고 계시다면 <a href=\"https://developer.nvidia.com/cuda-11.0-download-archive\">공식 홈페이지</a>를 참고하시면 됩니다.</em></p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token function\">wget</span> https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\n<span class=\"token function\">sudo</span> <span class=\"token function\">mv</span> cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\n<span class=\"token function\">wget</span> http://developer.download.nvidia.com/compute/cuda/11.0.2/local_installers/cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb\n<span class=\"token function\">sudo</span> dpkg -i cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb\n<span class=\"token function\">sudo</span> apt-key <span class=\"token function\">add</span> /var/cuda-repo-ubuntu1804-11-0-local/7fa2af80.pub\n<span class=\"token function\">sudo</span> <span class=\"token function\">apt-get</span> update\n<span class=\"token function\">sudo</span> <span class=\"token function\">apt-get</span> -y <span class=\"token function\">install</span> cuda</code></pre></div>\n<p>설치가 완료되었다면 driver API와 CUDA toolkit이 각각 버전 11으로 올바르게 인식되는지 확인합시다. <code class=\"language-text\">nvidia-smi</code> 명령어를 사용하면 driver API의 버전을 확인할 수 있습니다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 534px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/fef7a23a3b0ad24907e92b36514cff70/a07a7/20-11-19-1.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 41.05263157894738%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABdElEQVQoz3VRyW6DUAzkkFMgrAkQIOwhYatAVbNU7aH//1HTsav21oNlMX7MYhtlWaEqS5xOOfI8x/F4hGluEUUR0jT9w+M4Rsl3rufBt3b4ahp8EP8kdufsjRXYNoyu69Bfe5zPZ/i+rz+N44hhGND3PWQuggmFhLQn3tQ1OhK+Lgt7i/F6RVtVaIkZh8MBUmEYKqGUuMuyDFmawXNdbDYbOOziXt4JcRhG6j7Y7xETn+aZiRIYSZKgJHtN1UpU2pa9huASta4bTNOkThs6kO+iyJFyLkZEXETkraQ0UjoRgqoqFSyLgoNOHc5U3dPBsqxY11UJF/aeEV3Hhef5iEm4NU2dyaqM3W6H/8rmkj0ewbIsLcF+exAEsB1b3ziOw3J1RUbC3JfLRVU7Oht4iGma1e0LHZ7yAo/HE+/Ppzq+3e7sEw4k9FkSWUhlXerQ4xFk8aJiS1Hd9wN1JpcVR7bt6J5czn8OEsIh9ptguzX1YBL7G5py0xelBy0sAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/fef7a23a3b0ad24907e92b36514cff70/15813/20-11-19-1.webp 190w,\n/static/fef7a23a3b0ad24907e92b36514cff70/1cdb2/20-11-19-1.webp 380w,\n/static/fef7a23a3b0ad24907e92b36514cff70/29722/20-11-19-1.webp 534w\"\n              sizes=\"(max-width: 534px) 100vw, 534px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/fef7a23a3b0ad24907e92b36514cff70/a2d4f/20-11-19-1.png 190w,\n/static/fef7a23a3b0ad24907e92b36514cff70/3f520/20-11-19-1.png 380w,\n/static/fef7a23a3b0ad24907e92b36514cff70/a07a7/20-11-19-1.png 534w\"\n            sizes=\"(max-width: 534px) 100vw, 534px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/fef7a23a3b0ad24907e92b36514cff70/a07a7/20-11-19-1.png\"\n            alt=\"img\"\n            title=\"img\"\n            loading=\"lazy\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n  </a>\n    </span></p>\n<p><code class=\"language-text\">nvcc -V</code> 명령어를 사용하면 CUDA toolkit의 버전을 확인할 수 있습니다. (전 11.0을 설치했는데 왜 11.1이 설치되었을까요..? 흠🤔)<em>참고로 <code class=\"language-text\">nvidia-smi</code>와 <code class=\"language-text\">nvcc -V</code>가 서로 다른 버전을 보이는 이유는 <a href=\"https://stackoverflow.com/questions/53422407/different-cuda-versions-shown-by-nvcc-and-nvidia-smi\">이곳</a>을 확인하시면 좋습니다.</em></p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 423px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/5c7aafd55dcfff603716b124324060d9/f687d/20-11-19-3.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 23.684210526315788%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABDUlEQVQY02WPS0/CQBSFWWAaHkYbgpSAlHb6mr6gw6OSGhM3Ltwb3Pn/f8XnbQPGhMXJnTO58805vdD1eNjHWD/vWN+v3J2bTv12im/vlnnE+nmFM59j248MBgPG4zGj0ahTe76q53seVX1A1zsCU5DITGuDPlYUTU31dkKFijzLUL7P03TaQa+AG6BOU9JEE3mKYO1TZgWRCjgaQ7U1bMoNiezoPKPa71muXKazGX3LwhoOb5L2AnmcyoOyLDECUUrS5DlxHFGGIc1my0n8QXYq8dFiQSjVt0FI4DgML/X/ErYArTMyqeS6Kzz5IJc0hfgPrfkyO86S7DNOaJwZx8mk04tUN7bNfZvuH/AXVHKKPLlxK+4AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/5c7aafd55dcfff603716b124324060d9/15813/20-11-19-3.webp 190w,\n/static/5c7aafd55dcfff603716b124324060d9/1cdb2/20-11-19-3.webp 380w,\n/static/5c7aafd55dcfff603716b124324060d9/2c5ea/20-11-19-3.webp 423w\"\n              sizes=\"(max-width: 423px) 100vw, 423px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/5c7aafd55dcfff603716b124324060d9/a2d4f/20-11-19-3.png 190w,\n/static/5c7aafd55dcfff603716b124324060d9/3f520/20-11-19-3.png 380w,\n/static/5c7aafd55dcfff603716b124324060d9/f687d/20-11-19-3.png 423w\"\n            sizes=\"(max-width: 423px) 100vw, 423px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/5c7aafd55dcfff603716b124324060d9/f687d/20-11-19-3.png\"\n            alt=\"img\"\n            title=\"img\"\n            loading=\"lazy\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n  </a>\n    </span></p>\n<p>만약 <code class=\"language-text\">nvcc -V</code> 명령어를 사용했는데 위와 같이 버전이 출력되지 않는다면, 새로운 버전의 경로를 올바르게 인식할 수 있도록 계정의 .bashrc 파일 내 PATH를 수정해야 합니다. 먼저 .bashrc파일을 편집기를 통해 열어줍니다. </p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token function\">vim</span> ~/.bashrc</code></pre></div>\n<p>그리고 .bashrc 파일 하단에 아래 코드를 추가합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token comment\"># NVIDIA CUDA toolkit</span>\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\"><span class=\"token environment constant\">PATH</span></span><span class=\"token operator\">=</span>/usr/local/cuda-11/bin:<span class=\"token environment constant\">$PATH</span>\t\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">LD_LIBRARY_PATH</span><span class=\"token operator\">=</span>/usr/local/cuda-11/lib64</code></pre></div>\n<p>마지막으로, 변경된 .bashrc 파일의 내용을 적용합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token builtin class-name\">source</span> ~/.bashrc</code></pre></div>\n<h5>3. cudnn 8 설치</h5>\n<p> CUDA 버전 11이상을 사용하기 위해서 cudnn 또한 버전 8이상을 사용해야 합니다. <a href=\"https://developer.nvidia.com/cudnn\">공식 홈페이지</a>에서 cudnn 라이브러리를 다운 받아야 하며, NVIDIA 계정 필요합니다. NVIDIA 계정을 통해 본인 환경에 맞는 cudnn 라이브러리 tgz 파일을 다운로드 한 뒤에, 해당 파일을 압축 해제합니다. <em>명령어 내  x 표시가 되어있는 부분은 본인 환경에 맞는 버전으로 꼭 수정해 주시길 바랍니다.</em></p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token function\">tar</span> -xzvf cudnn-x.x-linux-x64-v8.x.x.x.tgz</code></pre></div>\n<p>그리고 압축 해제된 cudnn 관련 파일의 위치를 cuda 디렉토리로 이동시키고 사용권한도 변경해줍니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token function\">sudo</span> <span class=\"token function\">cp</span> cuda/include/cudnn*.h /usr/local/cuda/include\n<span class=\"token function\">sudo</span> <span class=\"token function\">cp</span> cuda/lib64/libcudnn* /usr/local/cuda/lib64\n<span class=\"token function\">sudo</span> <span class=\"token function\">chmod</span> a+r /usr/local/cuda/include/cudnn*.h /usr/local/cuda/lib64/libcudnn*</code></pre></div>\n<p>cudnn 버전을 확인하여 CUDNN_MAJOR 8이 출력된다면 설치가 완료된 것입니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token function\">cat</span> /usr/local/cuda/include/cudnn_version.h <span class=\"token operator\">|</span> <span class=\"token function\">grep</span> CUDNN_MAJOR -A <span class=\"token number\">2</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 754px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/d28be3ba75a0672d91413e7ecbb17d4b/7527b/20-11-19-4.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 17.36842105263158%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAApklEQVQI12WNywrCMBREuxFsm5CkSZP0QUuqEikUiyLiwo0L//+PxiTSlYvDDAP33Ox9WfG6Lfg8r3jcF9BTj92hBekNBOMQQqCqKkgpE7FHtr2ua1hrU1JKkXnvMZ88Vj/jPB3RCwm9LyEIBRdR+BMwxhKbjHOOoiiQR/I8ZVmWyIZhRNt1cNOE0Tm4pgnSCiocqvjdWLRhU0olmtCNMdBagxDyxxdlAEuCJHlFEwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/d28be3ba75a0672d91413e7ecbb17d4b/15813/20-11-19-4.webp 190w,\n/static/d28be3ba75a0672d91413e7ecbb17d4b/1cdb2/20-11-19-4.webp 380w,\n/static/d28be3ba75a0672d91413e7ecbb17d4b/20eb0/20-11-19-4.webp 754w\"\n              sizes=\"(max-width: 754px) 100vw, 754px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/d28be3ba75a0672d91413e7ecbb17d4b/a2d4f/20-11-19-4.png 190w,\n/static/d28be3ba75a0672d91413e7ecbb17d4b/3f520/20-11-19-4.png 380w,\n/static/d28be3ba75a0672d91413e7ecbb17d4b/7527b/20-11-19-4.png 754w\"\n            sizes=\"(max-width: 754px) 100vw, 754px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/d28be3ba75a0672d91413e7ecbb17d4b/7527b/20-11-19-4.png\"\n            alt=\"img\"\n            title=\"img\"\n            loading=\"lazy\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n  </a>\n    </span></p>\n<h5>4. tf-nightly 설치</h5>\n<p>현재 tensorflow의 공식 버전은 2.3.0이지만, CUDA 버전 11은 tensorflow 버전 2.5.0부터 지원되기 때문에 tensorflow 대신 tf-nightly를 사용해야 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">pip <span class=\"token function\">install</span> tf-nightly<span class=\"token operator\">==</span><span class=\"token number\">2.5</span>.0.dev20201116</code></pre></div>\n<p>tf-nightly는 매일 개발이 진행되고 있는 버전의 tensorflow라고 생각하시면 됩니다. 매우 최신 기능이 지원되기는 하나 불안정하다는 단점이 있습니다. <em>개발 진행 날짜에 따라 'dev2020xxxx' 부분이 다를 수 있습니다.</em></p>\n<h5>5. libcusolver.so.10 에러 해결</h5>\n<center><i>해당 에러가 발생하지 않는 분들은 이 파트 전체를 건너 뛰시면 됩니다.</i></center><br>\n<p>현재 CUDA 버전 11 환경에서 tf-nightly 2.5.0을 사용하려고 하면 아래와 같은 에러로그가 출력되는 경우가 있습니다. 이는 CUDA toolkit 10.1에 존재하는 libcusolver.so.10 파일을 불러오지 못해서 발생하는 에러입니다. (CUDA 10을 지우고.. 11을 설치했는데.. 10.1을 또 설치하라는 말입니까..? 😭) 이 뿐만 아니라 가끔 cudnn 버전 8에 존재하는 파일 또한 제대로 불러오지 못하는 경우도 존재합니다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 760px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/77a5b2b7b647601af18814c22a64c57f/5dded/20-11-19-5.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 19.473684210526315%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAxElEQVQY0z2PW2+DMBSDeaqA5tpcIRCYNE1T1e3//zvPCeoePtlKcuyTIYaAnDNSSlioWut/lJKXykuNMZD0SikIITqye9nVWIshLQuWUpDXFVutcCwQvLxzcObAXXKAvANb2DuwFT40g+ibRucwfJcFP2fF78eBZy34WhOee0E7fx17181ZOD4OLPPeI8YIy20e5AwO1Wqc3uJzzRhKiji44c5Nz31DDh7eGtjWTlq7mCbM89yZ6BvjOF7Q36i3ceo/+QMYJGD5TbBWdgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/77a5b2b7b647601af18814c22a64c57f/15813/20-11-19-5.webp 190w,\n/static/77a5b2b7b647601af18814c22a64c57f/1cdb2/20-11-19-5.webp 380w,\n/static/77a5b2b7b647601af18814c22a64c57f/9046c/20-11-19-5.webp 760w,\n/static/77a5b2b7b647601af18814c22a64c57f/c89f9/20-11-19-5.webp 1140w,\n/static/77a5b2b7b647601af18814c22a64c57f/7afe4/20-11-19-5.webp 1520w,\n/static/77a5b2b7b647601af18814c22a64c57f/7d35d/20-11-19-5.webp 1588w\"\n              sizes=\"(max-width: 760px) 100vw, 760px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/77a5b2b7b647601af18814c22a64c57f/a2d4f/20-11-19-5.png 190w,\n/static/77a5b2b7b647601af18814c22a64c57f/3f520/20-11-19-5.png 380w,\n/static/77a5b2b7b647601af18814c22a64c57f/3c051/20-11-19-5.png 760w,\n/static/77a5b2b7b647601af18814c22a64c57f/b5cea/20-11-19-5.png 1140w,\n/static/77a5b2b7b647601af18814c22a64c57f/891d5/20-11-19-5.png 1520w,\n/static/77a5b2b7b647601af18814c22a64c57f/5dded/20-11-19-5.png 1588w\"\n            sizes=\"(max-width: 760px) 100vw, 760px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/77a5b2b7b647601af18814c22a64c57f/3c051/20-11-19-5.png\"\n            alt=\"img\"\n            title=\"img\"\n            loading=\"lazy\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n  </a>\n    </span></p>\n<p>아나콘다 가상환경을 사용하는 분들은 아래의 명령어를 통해 이 문제를 쉽게 해결할 수 있습니다. 가상환경 위에 설치하는 것이 충돌이 날 확률도 적고 문제가 생겼을 때 삭제하기도 쉬워서, 웬만하면 이 방법을 사용하는 것을 추천드립니다. <em>다만 새로운 가상환경을 만드실 때 마다 해당 env에 아래의 패키지를 설치해주셔야 합니다.</em></p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">conda <span class=\"token function\">install</span> cudatoolkit\t\t<span class=\"token comment\"># CUDA 파일 관련 에러 해결</span>\nconda <span class=\"token function\">install</span> -c nvidia cudnn\t<span class=\"token comment\"># cudnn 8 파일 관련 에러 해결</span></code></pre></div>\n<center><i>아나콘다 가상환경을 통해 에러를 해결하신 분들은 아래 파트를 건너 뛰시면 됩니다.</i></center><br>\n<p>아나콘다 가상환경을 사용하지 않는 경우에는 CUDA toolkit 10.1을 설치하여 libcusolver.so.10 파일을 인식할 수 있도록 했습니다. 이 방법은 임시 방편이기 때문에 저는 추후에 CUDA 버전이 안정화가 되면 CUDA를 다시 설치하려 생각하고 있습니다.<em>혹은 <a href=\"http://ejklike.github.io/2019/08/19/insatall-tensorflow-2.0.0-beta1-in-ubuntu-with-cuda-10-1.html\">이곳</a>을 참고하는 것도 좋아보입니다.</em></p>\n<p>아래의 명령어를 사용하여 CUDA toolkit 10.1 설치를 진행합니다. 설치 과정에서 cuda 폴더를 업데이트 할 지에 대한 질문이 있었는데, 충돌이 생길까 걱정되어서 NO를 선택했습니다. </p>\n<p><em>주의: 아래의 명령어는 ubuntu 18.04 x86_64 운영체제를 위한 설치 명령어입니다. 다른 운영체제를 사용하고 계시다면 <a href=\"https://developer.nvidia.com/cuda-10.1-download-archive-base\">공식 홈페이지</a>를 참고하시면 됩니다.</em></p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token function\">wget</span> https://developer.nvidia.com/compute/cuda/10.1/Prod/local_installers/cuda_10.1.105_418.39_linux.run\n<span class=\"token function\">sudo</span> <span class=\"token function\">sh</span> cuda_10.1.105_418.39_linux.run</code></pre></div>\n<p>.bashrc 파일의 PATH를 수정하여 CUDA toolkit 10.1을 올바르게 인식할 수 있도록 합시다. 먼저 .bashrc파일을 편집기를 통해 열어줍니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token function\">vim</span> ~/.bashrc</code></pre></div>\n<p>그리고 .bashrc 파일의 CUDA 11버전 PATH 하단에 아래 코드를 추가합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">LD_LIBRARY_PATH</span><span class=\"token operator\">=</span><span class=\"token variable\">${LD_LIBRARY_PATH}</span>:/usr/local/cuda-10.1/lib64</code></pre></div>\n<p>마지막으로, 변경된 .bashrc 파일의 내용을 적용합니다. 여기까지 모두 완료하셨다면 이제 거의 다 끝났습니다😆</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token builtin class-name\">source</span> ~/.bashrc</code></pre></div>\n<h3>테스트</h3>\n<p>이제 RTX 3090 GPU가 tf-nightly 2.5.0에서 잘 작동하는지 확인해봅시다. 다음의 코드를 통해서 GPU의 사용 가능 여부를 확인할 수 있습니다. 저는 python 3.8과 3.6 버전에서 각각 확인해보았으며 모두 잘 동작하였습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>python<span class=\"token punctuation\">.</span>client <span class=\"token keyword\">import</span> device_lib\n\ntf<span class=\"token punctuation\">.</span>test<span class=\"token punctuation\">.</span>is_gpu_available<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\t\t<span class=\"token comment\"># 사용 가능한 GPU가 있는지 확인: True</span>\ndevice_lib<span class=\"token punctuation\">.</span>list_local_devices<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\t<span class=\"token comment\"># 사용 가능한 모든 디바이스를 출력: RTX 3090 정보 출력</span></code></pre></div>\n<p>모든 디바이스를 출력하는것이 아니라 장착한 GPU의 번호만 간단하게 출력하는 <a href=\"https://stackoverflow.com/questions/38559755/how-to-get-current-available-gpus-in-tensorflow\">방법</a>은 아래 코드를 사용하시면 됩니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>python<span class=\"token punctuation\">.</span>client <span class=\"token keyword\">import</span> device_lib\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">get_available_gpus</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    local_device_protos <span class=\"token operator\">=</span> device_lib<span class=\"token punctuation\">.</span>list_local_devices<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> <span class=\"token punctuation\">[</span>x<span class=\"token punctuation\">.</span>name <span class=\"token keyword\">for</span> x <span class=\"token keyword\">in</span> local_device_protos <span class=\"token keyword\">if</span> x<span class=\"token punctuation\">.</span>device_type <span class=\"token operator\">==</span> <span class=\"token string\">'GPU'</span><span class=\"token punctuation\">]</span>\n\nget_available_gpus<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>이 외에도 간단한 실습코드를 돌려보면서 이전 GPU와 비교해서 얼마나 빠르게 학습이 진행되는지, GPU를 충분히 활용하고 있는지를 확인해보시길 바랍니다. 저는 '핸즈온 머신러닝' 책의 <a href=\"https://github.com/ageron/handson-ml2/blob/master/10_neural_nets_with_keras.ipynb\">예제코드</a>를 돌려보았고 잘 동작하는 것을 확인했습니다. </p>\n<p>혹시 코드의 디버깅 로그가 너무 잡다하게 출력되는 경우에는 python의 os모듈을 통해 로그를 출력하지 않도록 바꾸시면 편리합니다. </p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\nos<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">[</span><span class=\"token string\">'TF_CPP_MIN_LOG_LEVEL'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">'3'</span> \n<span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf</code></pre></div>\n<ul>\n<li>0 = all messages are logged (default behavior)</li>\n<li>1 = INFO messages are not printed</li>\n<li>2 = INFO and WARNING messages are not printed</li>\n<li>3 = INFO, WARNING, and ERROR messages are not printed</li>\n</ul>\n<p>이제 딥러닝 실험에서 RTX 3090을 사용할 수 있게 되었습니다! 👏👏👏</p>\n<blockquote>\n<p>(21.01.06) 위의 tf.test.is<em>gpu</em>available() 에서는 값이 true가 나오더라도, 실제 예제 코드를 돌리면 에러를 뱉는 경우를 발견했습니다. 그래서 혹시 환경을 모두 구축하셨으면 실제 코드를 돌려가면서 gpu가 잘 활용되는지 확인해보시는 것을 추천드립니다. 저는 <a href=\"https://github.com/tensorflow/benchmarks/tree/master/scripts/tf_cnn_benchmarks\">tensorflow benchmark</a> 코드를 돌려보면서 gpu가 잘 활용되는지, 얼마나 빠르게 데이터를 처리하는지 등을 확인했습니다. 자세한 사용법은 해당 링크 readme에도 잘 나와있고, <a href=\"http://hiseon.me/data-analytics/tensorflow/tensorflow-benchmark/\">HiSEON님의 블로그</a>에도 잘 나와있으니 필요하신 분들은 참고하시길 바랍니다..!</p>\n</blockquote>\n<h3>Reference</h3>\n<ul>\n<li><a href=\"https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html\">NVIDIA cudnn documentation</a></li>\n<li><a href=\"https://medium.com/@dun.chwong/the-simple-guide-deep-learning-with-rtx-3090-cuda-cudnn-tensorflow-keras-pytorch-e88a2a8249bc\">The Simple Guide: Deep Learning with RTX 3090 (CUDA, cuDNN, Tensorflow, Keras, PyTorch)</a> </li>\n<li><a href=\"https://stackoverflow.com/questions/53422407/different-cuda-versions-shown-by-nvcc-and-nvidia-smi\">Different CUDA versions shown by nvcc and NVIDIA-smi</a></li>\n<li><a href=\"https://stackoverflow.com/questions/35911252/disable-tensorflow-debugging-information\">Disable Tensorflow debugging information</a></li>\n<li><a href=\"https://stackoverflow.com/questions/38559755/how-to-get-current-available-gpus-in-tensorflow\">How to get current available GPUs in tensorflow?</a></li>\n</ul>","frontmatter":{"path":"/deeplearning/20-11-19/","title":"RTX 3090을 사용한 딥러닝 실험환경 구축하기 (Ubuntu 18.04)","category":"Deep Learning","date":"2020-11-19"}}},"pageContext":{}},"staticQueryHashes":["2390655019","256249292","63159454"]}