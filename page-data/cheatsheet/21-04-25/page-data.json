{"componentChunkName":"component---src-templates-post-js","path":"/cheatsheet/21-04-25/","result":{"data":{"markdownRemark":{"html":"<p>공부하면서 알게 된 것들 중에서 포스팅으로 만들기에는 부담스러운 내용들을 이곳에 모아둡니다.</p>\n<p>다른 테크 블로그들의 TIL 처럼 매일매일 공부 내용을 기록하기보다는 그냥 제 맘대로 아무때나 업데이트 할 생각입니다! 나중에는 충분한 카테고리로 나눌 수 있을 정도로 내용이 엄청 많아졌으면 좋겠네요 ☺️ </p>\n<p>추가적으로, <a href=\"https://www.notion.so/Career-at-VoyagerX-833e2878660a4a7590b6946c0da8b151\">보이저엑스 인턴 채용 질문</a>을 간단하게 하나씩 채워가고 있습니다. 어쩌다가 발견하게 되었는데 제대로 알고 있다고 자신할 수 있는 내용이 그렇게 많지 않더라고요 💦</p>\n<blockquote>\n<p>최근에 작성한 내용들이 하단에 위치하도록 배열하였습니다.</p>\n</blockquote>\n<h3>Python</h3>\n<h5>🗓 2021.04.25</h5>\n<p><a href=\"https://docs.python.org/3/reference/simple_stmts.html#future\">파이썬 도큐먼트</a>의 <code class=\"language-text\">future</code> 문에 대한 설명을 읽었습니다. <code class=\"language-text\">future</code> 문은 미래 버전 파이썬의 기능들을 쉽게 마이그레이션(하나의 운영환경에서 다른 운영환경으로 옮기는 것)하기 위해 만들어졌습니다. import 뒤에 따라오는 new feature가 만약 파이썬 3의 기능이라고 하더라도 파이썬 2 버전에서 사용 가능하게 됩니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> __future__ <span class=\"token keyword\">import</span> print_function</code></pre></div>\n<h3>TensorFlow</h3>\n<h5>🗓 2021.04.25</h5>\n<p><a href=\"https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/map_fn\">텐서플로우 공식문서</a>의 <code class=\"language-text\">tf.map_fn</code> 함수에 대한 설명을 읽었습니다. dimension 0에서 unpack된 elems이라는 tensor list의 요소들을 fn에 map합니다. </p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">tf<span class=\"token punctuation\">.</span>map_fn<span class=\"token punctuation\">(</span>fn<span class=\"token punctuation\">,</span> elems<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> parallel_iterations<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> back_prop<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n    \t  swap_memory<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> infer_shape<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>MAML을 구현 할 때 meta-batch에 대한 cross entropy를 병렬적으로 계산하기 위해서 아래와 같은 코드를 사용할 수 있습니다. 여기서 xs의 shape은 [meta-batch size, nway*kshot, 84*84*3] 입니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">cent<span class=\"token punctuation\">,</span> acc <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>map_fn<span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> inputs<span class=\"token punctuation\">:</span> self<span class=\"token punctuation\">.</span>get_loss_single<span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">,</span> weights<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n\t\t\t\t\t elems<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>xs<span class=\"token punctuation\">,</span> ys<span class=\"token punctuation\">,</span> xq<span class=\"token punctuation\">,</span> yq<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n\t\t\t\t \t dtype<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n\t\t\t\t \t parallel_iterations<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>metabatch<span class=\"token punctuation\">)</span></code></pre></div>\n<h5>🗓 2021.04.27</h5>\n<p>모델 그래프를 빌드하는 함수에서 for loop를 많이 사용하면 이게 그대로 모델 training 단계에서도 매번 for loop가 적용되어 모델의 학습이 느려지겠구나라고 생각했었는데 곰곰히 생각해보니까 아니더라구요. </p>\n<p>빌드하는 단계에서는 for loop가 여러 번 돌더라도, 그래프의 각 노드들이 연결되고 난 뒤에는 빌드 된 그래프 구조 자체가 중요하지, 빌드 단계에서의 for loop는 관련이 없게 된다는 것을 문득 깨달았습니다. </p>\n<p>꽤나 오랫동안 아무렇지 않게 착각하고 있었어서 이 곳에 기록합니다. 시간날 때 한 번 간단한 구조에 대해서 for loop를 사용한 모델과, map_fn을 사용한 모델이 학습 상에서 큰 차이가 있는지 확인 해 봐야겠습니다 🧐 (그럼 map_fn은 어떤 경우에 메리트를 가질까..?!?)</p>\n<h5>🗓 2021.05.02</h5>\n<p>TensorFlow 1.15로 코드를 짜다가 <code class=\"language-text\">softmax_cross_entropy_with_logits</code>는 loss에 대한 2nd-order 계산을 지원하지만 <code class=\"language-text\">sparse_softmax_cross_entropy_with_logits</code>는 loss에 대한 2nd-order 계산을 지원하지 않는다는걸 알게 되었습니다. 이 둘의 차이는 label이 one-hot 형태로 주어지냐 아니냐의 차이밖에 없는데 이런 결과를 나타냈다는게 이상해서 찾아보다가 이미 tensorflow repository에 <a href=\"https://github.com/tensorflow/tensorflow/issues/5876\">관련 이슈</a>가 올라왔던 것을 발견했습니다.</p>\n<p>이슈를 읽어보니 일부 indexing 작업에 대한 도함수 계산이 아직 제대로 구현되지 않았거나, 몇 가지 operation에 대해서 2차 미분 계산이 개발자들도 아직 해결하지 못한 오류를 가진다고 말하고 있었습니다(구체적인 원인은 모르겠습니다). 이슈를 보면서, 0.2 버전에서 1.15 까지 개발이 진행되면서도 TensorFlow 팀이 지속적으로 해결하지 못하고 있는 문제점이 있다는 것이 신기했습니다.</p>\n<h3>Computer Science &#x26; Engineering</h3>\n<h5>🗓 2021.00.00</h5>\n<p>PNG와 JPG의 차이점은?</p>\n<p><a href=\"https://www.howtogeek.com/howto/30941/whats-the-difference-between-jpg-png-and-gif/\">https://www.howtogeek.com/howto/30941/whats-the-difference-between-jpg-png-and-gif/</a></p>\n<p><a href=\"https://undsgn.com/jpg-vs-png/\">https://undsgn.com/jpg-vs-png/</a></p>\n<p>시간 날 때 읽고 간단 요약만 하기</p>\n<h5>🗓 2021.00.00</h5>\n<p> Dynamic Programming이란?</p>\n<h5>🗓 2021.00.00</h5>\n<p>Virtual Memory란?</p>\n<h5>🗓 2021.00.00</h5>\n<p>Semaphore란?</p>\n<h5>🗓 2021.00.00</h5>\n<p>Cache란?</p>\n<h5>🗓 2021.00.00</h5>\n<p>Garbage Collection이란?</p>\n<h5>🗓 2021.00.00</h5>\n<p>Database Index 추가의 장단점은?</p>\n<h5>🗓 2021.00.00</h5>\n<p>NoSQL의 장단점은?</p>\n<h5>🗓 2021.00.00</h5>\n<p>공유기의 원리는?</p>\n<h5>🗓 2021.00.00</h5>\n<p>HTTP/2의 특성은?</p>\n<h5>🗓 2021.00.00</h5>\n<p>비대칭 암호화란?</p>\n<h5>🗓 2021.00.00</h5>\n<p>Node.js의 특징은?</p>\n<h5>🗓 2021.00.00</h5>\n<p>HDD, SSD, DRAM 각각의 성능은?</p>\n<h5>🗓 2021.00.00</h5>\n<p>Memory Leak 디버깅은?</p>\n<h5>🗓 2021.00.00</h5>\n<p>GIT의 장점은?</p>","frontmatter":{"path":"/cheatsheet/21-04-25/","title":"Today I Learned","category":"Cheat Sheet","date":"2021-04-25"}}},"pageContext":{}},"staticQueryHashes":["2390655019","256249292","63159454"]}