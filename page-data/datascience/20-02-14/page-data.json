{"componentChunkName":"component---src-templates-post-js","path":"/datascience/20-02-14/","result":{"data":{"markdownRemark":{"html":"<p>딥러닝 생성모델 공부에 있어서 가장 기초가 되는 autoencoder에 대해 알아보겠습니다. 'Generative Deep Learning' (O'REILLY) 책을 통해 공부한 내용을 중심으로 포스팅을 작성하였습니다.</p>\n<h3 id=\"autoencoder\" style=\"position:relative;\"><a href=\"#autoencoder\" aria-label=\"autoencoder permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Autoencoder?</h3>\n<center><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 700px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/3fb68572368c18bc334ef8d6dec0fee5/29d31/20-02-14-1.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 31.578947368421055%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAGABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAEF/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAAB2wUH/8QAFhABAQEAAAAAAAAAAAAAAAAAAQIA/9oACAEBAAEFAplMaRD/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAZEAACAwEAAAAAAAAAAAAAAAAAAREhMTL/2gAIAQEABj8C6bNLcn//xAAYEAEBAQEBAAAAAAAAAAAAAAABESEAMf/aAAgBAQABPyEFHTd4s2t6bV317//aAAwDAQACAAMAAAAQ8A//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAbEAEAAgMBAQAAAAAAAAAAAAABETEAIVFBgf/aAAgBAQABPxBSQuUZB8qsapNlhXPmbt0YwY5rP//Z'); background-size: cover; display: block;\"></span>\n  <picture>\n          <source srcset=\"/static/3fb68572368c18bc334ef8d6dec0fee5/15813/20-02-14-1.webp 190w,\n/static/3fb68572368c18bc334ef8d6dec0fee5/1cdb2/20-02-14-1.webp 380w,\n/static/3fb68572368c18bc334ef8d6dec0fee5/426ac/20-02-14-1.webp 700w\" sizes=\"(max-width: 700px) 100vw, 700px\" type=\"image/webp\">\n          <source srcset=\"/static/3fb68572368c18bc334ef8d6dec0fee5/82f15/20-02-14-1.jpg 190w,\n/static/3fb68572368c18bc334ef8d6dec0fee5/0246a/20-02-14-1.jpg 380w,\n/static/3fb68572368c18bc334ef8d6dec0fee5/29d31/20-02-14-1.jpg 700w\" sizes=\"(max-width: 700px) 100vw, 700px\" type=\"image/jpeg\">\n          <img class=\"gatsby-resp-image-image\" src=\"/static/3fb68572368c18bc334ef8d6dec0fee5/29d31/20-02-14-1.jpg\" alt=\"20 02 14 1\" title=\"20 02 14 1\" loading=\"lazy\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\">\n        </picture>\n  </a>\n    </span><p><i>https://blog.keras.io/building-autoencoders-in-keras.html</i></p></center>\n<p> Autoencoder는 입력 데이터를 저차원으로 인코딩합니다. 그리고 저차원으로 인코딩된 데이터를 다시 디코딩하여 원래의 상태로 재구성하는 구조를 가지고있습니다. 다시 얘기하자면 입력데이터를 인코더를 통해 저차원으로 차원 축소를 하고, 디코더를 통해 다시 원본 차원으로 복원하는 형태를 가지고 있습니다.</p>\n<p> 위의 이미지 처럼 2라는 숫자 이미지를 입력으로 받으면, 출력 값으로는 똑같은 2라는 이미지가 출력됩니다. 이 모델은 <strong>입력 이미지와 재구성된 이미지 사이의 손실을 최소화</strong>하는 가중치를 찾는 방향으로 훈련됩니다. 타겟 값이 입력 데이터와 같으므로 이를 self supervised learning 방식이라고 말하기도 합니다.</p>\n<h4 id=\"autoencoder의-특징\" style=\"position:relative;\"><a href=\"#autoencoder%EC%9D%98-%ED%8A%B9%EC%A7%95\" aria-label=\"autoencoder의 특징 permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Autoencoder의 특징</h4>\n<p> Autoencoder는 이제껏 <strong>훈련된 데이터와 비슷한 데이터</strong>만 입력으로 받을 수 있습니다. 데이터를 저차원으로 인코딩한다는 의미가 어떤 파일을 압축하는 알고리즘들과 같다는 의미가 아닙니다. 예를 들어, 이미지 압축 알고리즘은 일반적으로 이미지에 관한 압축이지만 특정한 종류의 이미지만 압축하기 위해 사용되지는 않습니다. 2라는 숫자 이미지를 압축하기 위해 학습된 모델은 사람 얼굴 사진같은 이미지는 올바르게 압축할 수 없습니다. 또한 최종적으로 디코딩을 거친 출력 결과는 대체로 원본 이미지보다 <strong>흐릿하게 출력</strong>됩니다.</p>\n<p> Autoencoder 하나만 가지고는 실제 응용 분야에서 많이 사용되지 않는 편이긴 하지만, autoencoder가 <strong>data denosing</strong>과 <strong>차원 축소</strong>라는 장점을 가지고 있기 때문에 이와 관련된 분야에서 사용됩니다.</p>\n<h4 id=\"high-dimension과-latent-space\" style=\"position:relative;\"><a href=\"#high-dimension%EA%B3%BC-latent-space\" aria-label=\"high dimension과 latent space permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>High dimension과 Latent space</h4>\n<p> Autoencoder에 대해서 제대로 이해하기 위해서는 <strong>high dimension과 latent space</strong>라는 용어에 대한 이해가 필수적입니다.</p>\n<p> 사진이 한 장 있다고 가정해보고 100x100 픽셀이라고 한다면, 이 데이터는 100x100x3 array입니다. 즉, [100, 100, 3] 이므로 숫자 3만개를 갖는 3차원 데이터가 되는데, 우리는 이 사진 한장을 3만 차원의 공간에 존재하는 점 하나로 볼 수 있습니다. 축 3만 개를 갖는 공간(= 3만 차원의 공간)에서 사진 한장은 3만 개의 숫자로 이루어져 있으므로 숫자들에 따라 점 하나로 위치할 수 있게됩니다. 이 때의 3만 차원을 high dimension이라 하고, 사진 한 장이 위치하게 되는 점이 data point가 됩니다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 760px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/ace05da908bd95f56ce0e6a454fda516/eea4a/20-02-14-2.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 40%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAIABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAEF/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAL/2gAMAwEAAhADEAAAAdsSoP/EABQQAQAAAAAAAAAAAAAAAAAAABD/2gAIAQEAAQUCf//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABQQAQAAAAAAAAAAAAAAAAAAABD/2gAIAQEABj8Cf//EABgQAAMBAQAAAAAAAAAAAAAAAAABIREx/9oACAEBAAE/IbRaLlP/2gAMAwEAAgADAAAAEPvv/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAGRABAAMBAQAAAAAAAAAAAAAAAQARITHR/9oACAEBAAE/EHfFZUBfVZc0tn//2Q=='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/ace05da908bd95f56ce0e6a454fda516/15813/20-02-14-2.webp 190w,\n/static/ace05da908bd95f56ce0e6a454fda516/1cdb2/20-02-14-2.webp 380w,\n/static/ace05da908bd95f56ce0e6a454fda516/9046c/20-02-14-2.webp 760w,\n/static/ace05da908bd95f56ce0e6a454fda516/c89f9/20-02-14-2.webp 1140w,\n/static/ace05da908bd95f56ce0e6a454fda516/af3f0/20-02-14-2.webp 1280w\"\n              sizes=\"(max-width: 760px) 100vw, 760px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/ace05da908bd95f56ce0e6a454fda516/82f15/20-02-14-2.jpg 190w,\n/static/ace05da908bd95f56ce0e6a454fda516/0246a/20-02-14-2.jpg 380w,\n/static/ace05da908bd95f56ce0e6a454fda516/307d7/20-02-14-2.jpg 760w,\n/static/ace05da908bd95f56ce0e6a454fda516/0470c/20-02-14-2.jpg 1140w,\n/static/ace05da908bd95f56ce0e6a454fda516/eea4a/20-02-14-2.jpg 1280w\"\n            sizes=\"(max-width: 760px) 100vw, 760px\"\n            type=\"image/jpeg\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/ace05da908bd95f56ce0e6a454fda516/307d7/20-02-14-2.jpg\"\n            alt=\"img\"\n            title=\"img\"\n            loading=\"lazy\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n  </a>\n    </span> </p>\n<p> 자 그러면 이 관점에서 autoencoder를 다시 들여다보면, 2라는 숫자 이미지를 학습하는 autoencoder 모델의 인풋 데이터는 결국 28x28 차원 상의 점 하나입니다. 인코더는 28x28차원의 점 하나를, 28x28차원 보다 낮은 차원인 <strong>저차원 잠재공간의 점 하나로 매핑</strong>하는 법을 학습하고, 디코더는 저차원 잠재공간의 점 하나를 <strong>28x28차원의 점으로 매핑</strong>하는 법을 학습하게 됩니다. 결국 autoencoder는 이 과정을 통해 차원을 축소시키고 노이즈를 제거하는 효과를 얻게됩니다. 그리고 이 때의 저차원 잠재공간을 <strong>latent space</strong>, 저차원 잠재공간 상의 점 하나를 <strong>표현벡터(representation vector)</strong>라고 말합니다.</p>\n<h3 id=\"code-level-구현\" style=\"position:relative;\"><a href=\"#code-level-%EA%B5%AC%ED%98%84\" aria-label=\"code level 구현 permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Code-level 구현</h3>\n<p> 'Generative Deep Learning' (O'REILLY)의 저자가 깃허브에 제공한 <a href=\"https://github.com/davidADSP/GDL_code\">Keras 코드</a>를 통해 코드 레벨에서 autoencoder를 직접 학습시켜 봅시다. 모든 코드를 살펴보기보다는 중요한 부분만 골라서 어떤 형태를 가지고 있는지 살펴보겠습니다. 구현 코드는 개발자마다 달라질 수 있으니 대충 이런 구조구나 하고 감만 잡으시는 것을 추천드립니다. (dataset으로는 <strong>MNIST</strong>를 사용하였습니다.)</p>\n<ol>\n<li>인풋 데이터를 로드하고, 안정적인 학습을 위해 스케일을 조정하는 메소드입니다.</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">load_mnist</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span> y_test<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> mnist<span class=\"token punctuation\">.</span>load_data<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    x_train <span class=\"token operator\">=</span> x_train<span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span><span class=\"token string\">'float32'</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token number\">255</span><span class=\"token punctuation\">.</span>\n    x_train <span class=\"token operator\">=</span> x_train<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">.</span>shape <span class=\"token operator\">+</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    x_test <span class=\"token operator\">=</span> x_test<span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span><span class=\"token string\">'float32'</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token number\">255</span><span class=\"token punctuation\">.</span>\n    x_test <span class=\"token operator\">=</span> x_test<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">.</span>shape <span class=\"token operator\">+</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">return</span> <span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span> y_test<span class=\"token punctuation\">)</span></code></pre></div>\n<ol start=\"2\">\n<li>인코더의 구조입니다. 합성곱 신경망과 LeakyRelu 활성화 함수를 반복하여 사용하여 모델을 구성하였습니다. 마지막 합성곱의 출력은 Flatten을 통해 펼치고 z<em>dim차원 잠재공간을 표현하기 위해 크기가 z</em>dim인 Dense 층에 연결합니다.</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\">### THE ENCODER</span>\n        encoder_input <span class=\"token operator\">=</span> Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>input_dim<span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span><span class=\"token string\">'encoder_input'</span><span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> encoder_input\n        x <span class=\"token operator\">=</span> Conv2D<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>encoder_conv_filters<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                   kernel_size<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>encoder_conv_kernel_size<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                   strides<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>encoder_conv_strides<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                   padding<span class=\"token operator\">=</span><span class=\"token string\">'same'</span><span class=\"token punctuation\">,</span>\n                   name<span class=\"token operator\">=</span><span class=\"token string\">'encoder_conv_'</span> <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> LeakyReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> Conv2D<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>encoder_conv_filters<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                   kernel_size<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>encoder_conv_kernel_size<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                   strides<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>encoder_conv_strides<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                   padding<span class=\"token operator\">=</span><span class=\"token string\">'same'</span><span class=\"token punctuation\">,</span>\n                   name<span class=\"token operator\">=</span><span class=\"token string\">'encoder_conv_'</span> <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> LeakyReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> Conv2D<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>encoder_conv_filters<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                   kernel_size<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>encoder_conv_kernel_size<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                   strides<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>encoder_conv_strides<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                   padding<span class=\"token operator\">=</span><span class=\"token string\">'same'</span><span class=\"token punctuation\">,</span>\n                   name<span class=\"token operator\">=</span><span class=\"token string\">'encoder_conv_'</span> <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> LeakyReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> Conv2D<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>encoder_conv_filters<span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                   kernel_size<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>encoder_conv_kernel_size<span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                   strides<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>encoder_conv_strides<span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                   padding<span class=\"token operator\">=</span><span class=\"token string\">'same'</span><span class=\"token punctuation\">,</span>\n                   name<span class=\"token operator\">=</span><span class=\"token string\">'encoder_conv_'</span> <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> LeakyReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        shape_before_flattening <span class=\"token operator\">=</span> K<span class=\"token punctuation\">.</span>int_shape<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span>\n        x <span class=\"token operator\">=</span> Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        encoder_output <span class=\"token operator\">=</span> Dense<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>z_dim<span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span><span class=\"token string\">'encoder_output'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n\n        self<span class=\"token punctuation\">.</span>encoder <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">(</span>encoder_input<span class=\"token punctuation\">,</span> encoder_output<span class=\"token punctuation\">)</span></code></pre></div>\n<ol start=\"3\">\n<li>디코더의 구조입니다. 전치 합성곱 신경망(conv transpose)과 LeakyRelu 활성화 함수를 반복하여 사용하여 모델을 구성하였습니다. 디코더가 인코더와 완전히 반대 구조를 가질 필요는 없이, 최종 출력층의 크기만 입력데이터의 크기와 맞춰주면 어떤 구조도 가능합니다. </li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"> <span class=\"token comment\">### THE DECODER</span>\n        decoder_input <span class=\"token operator\">=</span> Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>z_dim<span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span><span class=\"token string\">'decoder_input'</span><span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> Dense<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>prod<span class=\"token punctuation\">(</span>shape_before_flattening<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>decoder_input<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> Reshape<span class=\"token punctuation\">(</span>shape_before_flattening<span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> Conv2DTranspose<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>decoder_conv_t_filters<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                            kernel_size<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>decoder_conv_t_kernel_size<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                            strides<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>decoder_conv_t_strides<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                            padding<span class=\"token operator\">=</span><span class=\"token string\">'same'</span><span class=\"token punctuation\">,</span>\n                            name<span class=\"token operator\">=</span><span class=\"token string\">'decoder_conv_t_'</span> <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> LeakyReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> Conv2DTranspose<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>decoder_conv_t_filters<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                            kernel_size<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>decoder_conv_t_kernel_size<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                            strides<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>decoder_conv_t_strides<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                            padding<span class=\"token operator\">=</span><span class=\"token string\">'same'</span><span class=\"token punctuation\">,</span>\n                            name<span class=\"token operator\">=</span><span class=\"token string\">'decoder_conv_t_'</span> <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> LeakyReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> Conv2DTranspose<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>decoder_conv_t_filters<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                            kernel_size<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>decoder_conv_t_kernel_size<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                            strides<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>decoder_conv_t_strides<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                            padding<span class=\"token operator\">=</span><span class=\"token string\">'same'</span><span class=\"token punctuation\">,</span>\n                            name<span class=\"token operator\">=</span><span class=\"token string\">'decoder_conv_t_'</span> <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> LeakyReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> Conv2DTranspose<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>decoder_conv_t_filters<span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                            kernel_size<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>decoder_conv_t_kernel_size<span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                            strides<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>decoder_conv_t_strides<span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                            padding<span class=\"token operator\">=</span><span class=\"token string\">'same'</span><span class=\"token punctuation\">,</span>\n                            name<span class=\"token operator\">=</span><span class=\"token string\">'decoder_conv_t_'</span> <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> Activation<span class=\"token punctuation\">(</span><span class=\"token string\">'sigmoid'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        decoder_output <span class=\"token operator\">=</span> x\n\n        self<span class=\"token punctuation\">.</span>decoder <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">(</span>decoder_input<span class=\"token punctuation\">,</span> decoder_output<span class=\"token punctuation\">)</span></code></pre></div>\n<h3 id=\"autoencoder의-한계점\" style=\"position:relative;\"><a href=\"#autoencoder%EC%9D%98-%ED%95%9C%EA%B3%84%EC%A0%90\" aria-label=\"autoencoder의 한계점 permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Autoencoder의 한계점</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 760px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/c34ebb867840475aa22b3f4a32ccfb0a/21b4d/20-02-14-3.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 20%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAIAAAABPYjBAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAy0lEQVQI1xWOOw5FUBiELcsCVBSikhwiQtAc73hF4ll4RIUl2JNWYhMacec2k5mcb/45zPM8x3Fs21aW5bqunuft+w4/zzNiXddN03RdV1XVNE3jOAZBgGgYxn3fzPu+oIui0DQtiiJBEOI4lmU5yzJEGFVVoY7juK4L5XkeJMuy53ky3/cty4J7YRj2fQ90GAZAGGzbFv08z/EKpZQmSWJZVpqmhJDruv5lQKZpouD7viiK2FQUBRzO6bpu2zam4GGASZKEP3Mch+UfGhx0m4E4HH4AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/c34ebb867840475aa22b3f4a32ccfb0a/15813/20-02-14-3.webp 190w,\n/static/c34ebb867840475aa22b3f4a32ccfb0a/1cdb2/20-02-14-3.webp 380w,\n/static/c34ebb867840475aa22b3f4a32ccfb0a/9046c/20-02-14-3.webp 760w,\n/static/c34ebb867840475aa22b3f4a32ccfb0a/c89f9/20-02-14-3.webp 1140w,\n/static/c34ebb867840475aa22b3f4a32ccfb0a/af3f0/20-02-14-3.webp 1280w\"\n              sizes=\"(max-width: 760px) 100vw, 760px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/c34ebb867840475aa22b3f4a32ccfb0a/a2d4f/20-02-14-3.png 190w,\n/static/c34ebb867840475aa22b3f4a32ccfb0a/3f520/20-02-14-3.png 380w,\n/static/c34ebb867840475aa22b3f4a32ccfb0a/3c051/20-02-14-3.png 760w,\n/static/c34ebb867840475aa22b3f4a32ccfb0a/b5cea/20-02-14-3.png 1140w,\n/static/c34ebb867840475aa22b3f4a32ccfb0a/21b4d/20-02-14-3.png 1280w\"\n            sizes=\"(max-width: 760px) 100vw, 760px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/c34ebb867840475aa22b3f4a32ccfb0a/3c051/20-02-14-3.png\"\n            alt=\"img\"\n            title=\"img\"\n            loading=\"lazy\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n  </a>\n    </span></p>\n<p> keras 코드를 통해 전체 모델을 학습시키고 난 뒤 위와 같은 결과를 얻었습니다. 저는 784차원의 고차원 이미지 데이터를 2차원의 잠재공간으로 매핑하였기 때문에 출력값이 좋지 않은 것 처럼 보이긴 하지만, 잠재공간의 차원을 10차원 정도로만 설정하여도 입력값과 상당히 비슷한 출력값을 얻어내실 수 있습니다. </p>\n<center><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 760px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/bc158fc22f52be12775f6963f1ea9843/21b4d/20-02-14-4.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 83.6842105263158%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAARCAYAAADdRIy+AAAACXBIWXMAAAsTAAALEwEAmpwYAAACS0lEQVQ4y42Uy2/UMBDG+//fOXKAS1UJCakCcSgCIQEHQIhSCYlty1bbbLebZrOPOLbHr49x7Oyju0hEGnnsTH6eLzP2kZCEldAgikYwxhw0okdzzfHOoX53BlVOEZ8QAo6S49G2LQ49HJOdLT+/IB8wffYE6vYmLXmPo5Cj4q6ewSGknaJ5F+BM9n2axzHSPX9MzqN6ewI1LTYZ9kDNEjo/A7uPbQI6m6wHdmERaFny11PQ/H5XctxNCIEe3mdmNMuSPKoASzlbn43VkHGY/T4DNQ/7GcaCJKkbYIR0MB1HnzJcZ8lrZFEUHzmZ/wBGmGo4C2nRSsOmYeN/7FX4BLyqvqGlxeMqB0gp1/+wy5B/uGwdJvMWI7HEQ9tAW+qkhvyNZeDF8gILvTicoc8ZdnIYKrVBsZhhUJcoxRzKyNwJIQMNvqwGqGl1GOi4OB3Icl+Sx1KsMKkGGM8GKOcFhFpx5jZ1AZtj4Pt6iIrEvyXHQGJg00iU1RQ3l99x9ekUfz6/wXI85GJR19SxMxz37utJgamS+0Cl1KZt4pzbqKwqFJc/MTw7Rnl9DpthfYzn+cn1BGMh9yXHk9L7jmWTJjTxnLcKVdVivvTQlE5J6IFcpOc/StzO1XqT/Sp38MBtwrKFQ1VbnP8yGI4sA30C9keRgccfZrib0WHJ2xeC5IYWbWCg77LbuRhyjPeEFy9rjO/0vuQIjLKttWsjSqP3dmc9muEKW6fx6ukM96MM9FvAKDleYRHcm9a9r7vLY9viuvMOTc13ozLrDP8C82stnuof/fMAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <picture>\n          <source srcset=\"/static/bc158fc22f52be12775f6963f1ea9843/15813/20-02-14-4.webp 190w,\n/static/bc158fc22f52be12775f6963f1ea9843/1cdb2/20-02-14-4.webp 380w,\n/static/bc158fc22f52be12775f6963f1ea9843/9046c/20-02-14-4.webp 760w,\n/static/bc158fc22f52be12775f6963f1ea9843/c89f9/20-02-14-4.webp 1140w,\n/static/bc158fc22f52be12775f6963f1ea9843/af3f0/20-02-14-4.webp 1280w\" sizes=\"(max-width: 760px) 100vw, 760px\" type=\"image/webp\">\n          <source srcset=\"/static/bc158fc22f52be12775f6963f1ea9843/a2d4f/20-02-14-4.png 190w,\n/static/bc158fc22f52be12775f6963f1ea9843/3f520/20-02-14-4.png 380w,\n/static/bc158fc22f52be12775f6963f1ea9843/3c051/20-02-14-4.png 760w,\n/static/bc158fc22f52be12775f6963f1ea9843/b5cea/20-02-14-4.png 1140w,\n/static/bc158fc22f52be12775f6963f1ea9843/21b4d/20-02-14-4.png 1280w\" sizes=\"(max-width: 760px) 100vw, 760px\" type=\"image/png\">\n          <img class=\"gatsby-resp-image-image\" src=\"/static/bc158fc22f52be12775f6963f1ea9843/3c051/20-02-14-4.png\" alt=\"20 02 14 4\" title=\"20 02 14 4\" loading=\"lazy\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\">\n        </picture>\n  </a>\n    </span><p><i>https://github.com/davidADSP/GDL_code</i></p></center>\n<p>MNIST dataset의 원본이미지가 인코더에 의해 잠재공간에 매핑된 표현벡터를 <strong>산포그래프(scatter plot)</strong>에 나타낸 것입니다. 우리가 사용한 예시 코드는 인코더가 이미지 데이터를 2차원 벡터로 매핑했기 때문에 이렇게 2차원상에 나타낼 수 있었습니다.</p>\n<p>이 잠재공간 상의 표현벡터를 디코더를 통해 매핑하여 원본 이미지 차원으로 복원하려고 할 때는 생각해보아야 할 몇 가지 문제점이 있습니다. </p>\n<ol>\n<li>잠재 공간에서 <strong>랜덤 포인트를 선택하기 위한 방법이 명확하지 않습니다.</strong> </li>\n<li><strong>생성된 이미지의 다양성이 부족</strong>합니다. 예를 들어 숫자 1의 영역이 숫자 8의 영역보다 훨씬 넓기에, 랜덤하게 포인트를 선택하면 1이 만들어질 확률이 더 높습니다. </li>\n<li>생성된 이미지의 <strong>품질이 상당히 나쁜 경우</strong>가 있습니다.</li>\n</ol>\n<p> 이 문제는 autoencoder가 잠재공간을 <strong>연속적으로 만들지 않기 때문에 발생</strong>합니다. (1, 1) 이라는 포인트가 훌륭하게 디코딩 되었다고해서 (1.1, 1.1) 또한 훌륭하게 디코딩 될 것이라는 보장이 없습니다. 그렇기 때문에 우리는 잠재공간을 연속적으로 만들어야 할 필요가 있습니다. 이에 대해서는 다음 포스팅 Variational Autoencoder에서 살펴보도록 하겠습니다. </p>\n<h3 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h3>\n<ul>\n<li>남세동님 <a href=\"https://www.facebook.com/dgtgrade/posts/1598044216921105\">페이스북 포스팅</a> (High dimensional data를 이해하는데 큰 도움을 받았습니다)</li>\n<li>데이비드 포스터 - Generative Deep Learning (O'REILLY)</li>\n<li><a href=\"https://blog.keras.io/building-autoencoders-in-keras.html\">The Keras Blog</a></li>\n</ul>","tableOfContents":"<ul>\n<li>\n<p><a href=\"/MachineLearning/20-02-14-Autoencoder/#autoencoder\">Autoencoder?</a></p>\n<ul>\n<li><a href=\"/MachineLearning/20-02-14-Autoencoder/#autoencoder%EC%9D%98-%ED%8A%B9%EC%A7%95\">Autoencoder의 특징</a></li>\n<li><a href=\"/MachineLearning/20-02-14-Autoencoder/#high-dimension%EA%B3%BC-latent-space\">High dimension과 Latent space</a></li>\n</ul>\n</li>\n<li><a href=\"/MachineLearning/20-02-14-Autoencoder/#code-level-%EA%B5%AC%ED%98%84\">Code-level 구현</a></li>\n<li><a href=\"/MachineLearning/20-02-14-Autoencoder/#autoencoder%EC%9D%98-%ED%95%9C%EA%B3%84%EC%A0%90\">Autoencoder의 한계점</a></li>\n<li><a href=\"/MachineLearning/20-02-14-Autoencoder/#reference\">Reference</a></li>\n</ul>","frontmatter":{"path":"/datascience/20-02-14/","title":"Autoencoder","category":"Deep Learning","date":"2020-02-14"}}},"pageContext":{}},"staticQueryHashes":["2390655019","256249292","63159454"]}